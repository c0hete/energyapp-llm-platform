# EnergyApp LLM Platform

**Chat LLM privado con Tool Calling y Base de Datos CIE-10**

Una plataforma mÃ©dica de chat basada en LLM ejecutado localmente con privacidad de datos garantizada. Incluye Tool Calling para bÃºsquedas automÃ¡ticas en base de datos CIE-10.

## CaracterÃ­sticas

- ğŸ¤– **LLM Privado**: Qwen 2.5:3b-instruct ejecutado localmente vÃ­a Ollama
- ğŸ”§ **Tool Calling**: BÃºsqueda automÃ¡tica de cÃ³digos CIE-10 mediante function calling
- ğŸ¥ **Base de Datos CIE-10**: 14,567 cÃ³digos mÃ©dicos con bÃºsqueda full-text
- ğŸ”’ **Privacidad**: Todos los datos permanecen en tu servidor
- ğŸ‘¥ **Multi-usuario**: Sistema de autenticaciÃ³n con sesiones y roles (usuario/admin)
- ğŸ’¬ **Conversaciones**: Historial completo de chats con streaming en tiempo real
- ğŸ›ï¸ **System Prompts**: MÃºltiples prompts configurables para diferentes especializaciones
- ğŸ“Š **Monitor del Sistema**: Panel de debug en tiempo real del flujo de Tool Calling
- ğŸ“± **Responsive**: Interfaz moderna y adaptativa con diseÃ±o premium
- ğŸŒ“ **Dark Mode**: DiseÃ±o oscuro optimizado para uso mÃ©dico
- âš¡ **Streaming**: Respuestas en tiempo real con soporte de herramientas

## Stack TecnolÃ³gico

### Frontend
- Next.js 16 (App Router) con Turbopack
- React 19
- TypeScript 5
- Tailwind CSS v4
- React Query (TanStack Query) para data fetching
- Zustand para state management
- Custom scrollbars y glassmorphism effects

### Backend
- FastAPI (Python)
- SQLAlchemy ORM
- PostgreSQL con full-text search
- Ollama API (Tool Calling con /api/chat)
- Caddy como reverse proxy
- Sistema de sesiones con cookies seguras
- Rate limiting con slowapi

### Infraestructura
- Servidor: Ubuntu 24.04 LTS
- Modelo LLM: Qwen 2.5:3b-instruct (1.9GB)
- Base de datos: PostgreSQL 16
- HTTPS con certificados SSL automÃ¡ticos (Caddy)

## InstalaciÃ³n

### Requisitos Previos
- Python 3.12+
- Node.js 18+
- PostgreSQL 16
- Ollama con modelo qwen2.5:3b-instruct

### Setup Backend

```bash
# Clonar repositorio
git clone https://github.com/c0hete/energyapp-llm-platform.git
cd energyapp-llm-platform

# Crear entorno virtual de Python
python3 -m venv .venv
source .venv/bin/activate  # En Windows: .venv\Scripts\activate

# Instalar dependencias
pip install -r requirements.txt

# Configurar base de datos PostgreSQL
createdb energyapp

# Cargar datos CIE-10 (si tienes el CSV)
python scripts/load_cie10.py data/cie10_codes.csv

# Iniciar backend
uvicorn src.main:app --host 0.0.0.0 --port 8001
```

### Setup Frontend

```bash
cd frontend
npm install
npm run build
npm start
```

### Setup Ollama

```bash
# Instalar Ollama (si no estÃ¡ instalado)
curl https://ollama.ai/install.sh | sh

# Descargar modelo
ollama pull qwen2.5:3b-instruct

# Verificar que funciona
ollama run qwen2.5:3b-instruct "Hola"
```

## Desarrollo

```bash
# Frontend - Desarrollo local
npm run dev

# Build para producciÃ³n
npm run build
npm start

# TypeScript check
npm run type-check
```

## Arquitectura

```
energyapp-llm-platform/
â”œâ”€â”€ frontend/                     # AplicaciÃ³n Next.js
â”‚   â”œâ”€â”€ app/                     # App Router structure
â”‚   â”‚   â”œâ”€â”€ (auth)/              # Rutas de autenticaciÃ³n
â”‚   â”‚   â””â”€â”€ (dashboard)/         # Rutas protegidas
â”‚   â”œâ”€â”€ components/              # React components
â”‚   â”‚   â”œâ”€â”€ ChatWindow.tsx       # Chat principal con streaming
â”‚   â”‚   â””â”€â”€ ToolCallingDebugPanel.tsx  # Monitor del sistema
â”‚   â”œâ”€â”€ hooks/                   # Custom React hooks
â”‚   â”‚   â”œâ”€â”€ useChatStream.ts     # Hook para chat con streaming
â”‚   â”‚   â””â”€â”€ useConversations.ts  # GestiÃ³n de conversaciones
â”‚   â”œâ”€â”€ lib/                     # Utilities y API client
â”‚   â””â”€â”€ store/                   # Zustand stores
â”œâ”€â”€ src/                         # Backend FastAPI
â”‚   â”œâ”€â”€ main.py                  # Endpoint principal /chat con Tool Calling
â”‚   â”œâ”€â”€ routes/                  # Rutas organizadas
â”‚   â”‚   â”œâ”€â”€ auth.py              # AutenticaciÃ³n y sesiones
â”‚   â”‚   â”œâ”€â”€ cie10.py             # API de cÃ³digos CIE-10
â”‚   â”‚   â””â”€â”€ prompts.py           # GestiÃ³n de system prompts
â”‚   â”œâ”€â”€ tools/                   # Tool Calling functions
â”‚   â”‚   â”œâ”€â”€ cie10_tools.py       # Herramientas CIE-10
â”‚   â”‚   â””â”€â”€ registry.py          # Registro de tools
â”‚   â”œâ”€â”€ ollama_client.py         # Cliente Ollama con /api/chat
â”‚   â””â”€â”€ models.py                # Modelos SQLAlchemy
â”œâ”€â”€ docs/                        # DocumentaciÃ³n tÃ©cnica
â”‚   â”œâ”€â”€ TOOL_CALLING_FINAL_FIX.md      # SoluciÃ³n completa
â”‚   â”œâ”€â”€ TOOL_CALLING_IMPLEMENTATION.md # ImplementaciÃ³n
â”‚   â””â”€â”€ CIE10_IMPLEMENTATION.md        # Base de datos CIE-10
â””â”€â”€ static/                      # Assets estÃ¡ticos
```

## DocumentaciÃ³n

- **[TOOL_CALLING_FINAL_FIX.md](docs/TOOL_CALLING_FINAL_FIX.md)**: SoluciÃ³n completa y funcionamiento del Tool Calling
- **[TOOL_CALLING_IMPLEMENTATION.md](docs/TOOL_CALLING_IMPLEMENTATION.md)**: GuÃ­a tÃ©cnica de implementaciÃ³n
- **[CIE10_IMPLEMENTATION.md](docs/CIE10_IMPLEMENTATION.md)**: Estructura de la base de datos CIE-10
- **[CONTEXT_*.md](docs/)**: DocumentaciÃ³n detallada por componente

## Licencia

Este proyecto estÃ¡ licenciado bajo la licencia MIT.

**Â© 2025 JosÃ© Alvarado Mazzei**

```
Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.
```

## Contacto

**Autor**: JosÃ© Alvarado Mazzei
**Email**: jose@alvaradomazzei.cl

---

**VersiÃ³n 1.0** | 2025
